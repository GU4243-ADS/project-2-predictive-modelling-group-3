---
title: "RandomForest"
author: "Sophie Beiers"
date: "2/24/2018"
output: html_document
---
The following script runs through random forest models based on the number of trees deemed best to predict well in the testing data. Each model is run on a different set of features, or combination of features. The model that predicted with the highest accuracy rate (76.6%) was the random forest model using SIFT features and 400 trees. 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("~/Documents/GitHub/project-2-predictive-modelling-group-3/doc")
```

## Load libraries
```{r}
if(!require("randomForest")){
  install.packages("randomForest")
}
if(!require("caret")){
  install.packages("caret")
}
if(!require("rfUtilities")){
  install.packages("rfUtilities")
}
if(!require("R.matlab")){
  install.packages("R.matlab")
}
library(randomForest)
library(caret)
library(rfUtilities)
library(R.matlab)
```


##1.  HOG features
The random forest model using HOG features performed with an accuracy rate of 74.8%. 
```{r}
features <- read.csv("../output/HOG_features.csv")
label.train <- read.csv("../output/label_train.csv",header=TRUE, as.is = TRUE)
label.train$x <- as.factor(label.train$x) # x is whether photo is dog or cat
```
```{r}
# training/testing
set.seed(2008)
in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-1]
training <- training[, -1]

y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]


```

```{r}
## Error testing: finding best number of trees 
## Based on code by: Yuting Ma (ADS Spring 2016)
train<- function(df, label, N){
  i = proc.time()
  fit <- randomForest::randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)

}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300, 400, 500, 600, 700, 800, 900)
# tried higher and lower, too. 2000 was too many tries
for(i in 1:9){

  fit <- train(training, y.train, N[i])
  pred_testing <- test(fit, testing)

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate")

}

```

```{r}
# best model
1 - min(errors) ## best model uses 700 trees with a predication accuracy rate of 0.748. 

# double check
#pred_testing <- test(fit, testing)
#1 - mean(pred_testing != as.factor(y.test))

# how long does it take? 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 700)) # 8.444 seconds elapsed 

system.time(pred_testing <- test(rf, testing)) # 0.80 seconds for prediction
```


## 2. Color Features
Not ideal. Took very long time with very little pay off. 
```{r}
# Training/Testing
features <- read.csv("../output/color_features.csv")

in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-1]
training <- training[, -1]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```

```{r}
# Error testing to choose best number of trees for model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300)

for(i in 1:3){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```
```{r}
# best model
1 - min(errors) ## best model used 300 trees with .67 accuracy -- not good. 

# how long does it take? 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 300)) ## 80.143  seconds is too long for this accuracy

system.time(pred_testing <- test(rf, testing)) # 0.36 seconds to predict
```

## 3. SIFT Features
This was the best model! With a prediction accuracy of 76.6%!
```{r}
# Training/Testing
features <- data_train

in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-1]
training <- training[, -1]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```

```{r}
# Error testing to choose best model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300, 400, 500, 600, 700, 800, 900)

for(i in 1:9){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```

```{r}
# best model
1 - min(errors) ## best model uses 400 trees with a predication accuracy rate of 0.766. 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 400)) # 4.616 seconds

system.time(pred_testing <- test(rf, testing)) # 0.043 seconds to predict
```

```{r}
randomforestmodel = randomForest(as.factor(y.train) ~ .,data = training, ntree = 600)
save(randomforestmodel, file = "randomforestSIFT.rda")
```



## 4. LBP Features
The below model is not ideal. Performed worse than using HOG or SIFT. 
```{r}
# Training/Testing 
features <- read.csv("../output/lbp-version2.csv")

in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-1]
training <- training[, -1]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```

```{r}
# Error testing to choose best model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300, 400, 500, 600, 700, 800, 900)

for(i in 1:9){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)
  
  na.action=na.exclude

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```

```{r}
# best model
1 - min(errors) ## best model uses 400 trees with a predication accuracy rate of 0.664. 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 400)) # 2.335 seconds elapsed

system.time(pred_testing <- test(rf, testing)) # 0.034
```


## 5. Combined SIFT & HOG
```{r}
# Training/Testing 
features <- read.csv("../output/SIFTHOG.csv")
features <- features[ ,-2]

in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-2]
training <- training[, -2]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```


```{r}
# Error testing to choose best model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300, 400, 500, 600, 700, 800, 900)

for(i in 1:9){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)
  
  na.action=na.exclude

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```

```{r}
# best model
#1 - min(errors) ## best model uses 900 trees with a predication accuracy rate of 0.748. 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 900)) # 4.808 seconds elapsed

save(rf, file = "../output/randomForest_train.rda")

#system.time(pred_testing <- test(rf, testing)) # 0.038

system.time(rf_all <- randomForest(as.factor(label.train[ ,2]) ~ ., 
                   data = features, ntree = 900))
save(rf_all, file = "../output/randomForest_full.rda")
```



## 6. Combined SIFT & HOG & LBP
```{r}
# Training/Testing 
features <- read.csv("../output/SIFTHOGLBP.csv")


in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-2]
training <- training[, -2]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```


```{r}
# Error testing to choose best model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200, 300, 400, 500, 600, 700, 800, 900)

for(i in 1:9){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)
  
  na.action=na.exclude

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```

```{r}
# best model
1 - min(errors) ## best model uses 300 trees with a predication accuracy rate of 0.74. 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 300)) # 5.539 seconds elapsed

system.time(pred_testing <- test(rf, testing)) # 0.041
```


## 7. Combined SIFT & HOG & LBP & Color
```{r}
# Training/Testing 
features <- read.csv("../output/SIFTHOGLBPCOLOR.csv")

in_train <- createDataPartition(y = label.train$x,
                                p = 3 / 4, 
                                list = FALSE)

training <- features[ in_train, ]
testing  <- features[-in_train, ]
testing <- testing[ ,-2]
training <- training[, -2]


y.train <- label.train[ in_train, 2 ]
y.test <- label.train[ -in_train, 2 ]

```


```{r}
# Error testing to choose best model 
train<- function(df, label, N){

  fit <- randomForest(as.factor(y.train) ~ ., data = training, importance = TRUE, ntree = N)
  return(fit)
}

test<- function(rfmodel, df){
  pred <-predict(rfmodel, newdata = df)
  return (pred)
}

errors <- c()
N <- c(100, 200)

for(i in 1:2){

  fit <- train(training, y.train, N[i])

  pred_testing <- test(fit, testing)
  
  na.action=na.exclude

  errors[i] <- mean(pred_testing != as.factor(y.test))
  cat(N[i]," trees has ", 1 - errors[i], "accuracy in prediction rate" )

}
```

```{r}
# best model
1 - min(errors) ## best model uses 200 trees with a predication accuracy rate of 0.724. 
system.time(rf <- randomForest(as.factor(y.train) ~ ., 
                   data = training, ntree = 200)) # 54.321 seconds elapsed

system.time(pred_testing <- test(rf, testing)) # 0.337 seconds to predict 
```